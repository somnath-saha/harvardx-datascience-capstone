---
title: "PH125.9x Choose Your Own Project: House Price Prediction"
author: "Somnath Saha"
date: "03/07/2021"
output: 
  pdf_document:
    number_sections: true
    toc: true
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

<!-------------------------------------------------------------------------------------------------------->
# Overview

This project is part of the final course - **Data Science: Capstone** in HarvardX's multi-part **Data Science Professional Certificate** series offered via the edX platform.

The project studies the dataset - **House Sales in King County, USA** available on Kaggle. The different features are studied and its impact evaluated on the pricing. Thus, a house price recommendation system is developed to predict the house prices. 

## About the dataset
The dataset - **House Sales in King County, USA: Predict house price using regression** is taken from Kaggle. \
Kaggle, a subsidiary of Google LLC, is an online community of data scientists and machine learning practitioners. Kaggle allows users to find and publish data sets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges. \
The dataset contains **21613** rows and **21** columns. \
**Go to kaggle page**: *<https://www.kaggle.com/harlfoxem/housesalesprediction>* 

## Goal of the project
The goal of the project is to exhaustively study the dataset and get valuable insights through data processing and visualization. Furthermore different ML algorithms are used to train a model that can predict house price.

\newpage

<!-------------------------------------------------------------------------------------------------------->
# Data analysis and visualization

## Brief look at edx dataset

### Structure of edx dataset: Column Names & Types
```{r, echo=TRUE, warning=FALSE, message=FALSE}
str(housedata)
```

### Data in edx dataset: First few rows
```{r, echo=TRUE, warning=FALSE, message=FALSE}
head(housedata)
```

<!-- Create plot theme to apply to ggplot2 element text throughout report-->
```{r, echo=FALSE, warning=FALSE, message=FALSE}
#TODO
```

## Plot distribution of ratings in the edx dataset
```{r, echo=FALSE}
edx %>% ggplot(aes(rating)) +
  geom_histogram(binwidth = 0.2, color = I("white"), fill = "skyblue") +
  scale_y_continuous(breaks = seq(0, 3000000, 500000), labels = sprintf("%sM", seq(0, 3, 0.5))) +
  scale_x_continuous(breaks = seq(0, 5, 0.5)) +
  labs(x = "Rating", y = "Count of Ratings", caption = caption_text) + plot_theme
```

## Plot average rating by movie in the edx dataset
```{r, echo=FALSE}
edx %>% group_by(movieId) %>%
  summarise(ave_rating = sum(rating)/n()) %>%
  ggplot(aes(ave_rating)) +
  geom_histogram(bins=30, color = I("white"), fill = "pink") +
  labs(x = "Average rating", y = "Number of movies", caption = caption_text) + plot_theme
```

## Separate individual genres and ranking them by the total number of ratings in the edx dataset
```{r, echo=FALSE, eval=TRUE}
edx %>% separate_rows(genres, sep = "\\|") %>%
  group_by(genres) %>%
  summarise("No. of Ratings" = n(), "Average Rating" = round(mean(rating), 3)) %>%
  arrange(desc("No. of Ratings")) %>% knitr::kable(caption = "Individual genres & their number of rankings")
```

## Plot average rating by genre for genre combinations with at least 50,000 ratings
```{r, echo=FALSE, warning=FALSE, message=FALSE}
edx %>% group_by(genres) %>%
        summarize(n = n(), avg = mean(rating), se = sd(rating)/sqrt(n())) %>%
        filter(n >= 50000) %>% 
        mutate(genres = reorder(genres, avg)) %>%
        ggplot(aes(x = genres, y = avg, ymin = avg - 2*se, ymax = avg + 2*se)) + 
        geom_point() +
        geom_errorbar() + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
        labs(x = "Genre combination", y = "Average Rating", caption = caption_text) + plot_theme
```

## Group and list top 10 movie titles based on number of ratings
```{r, echo=FALSE, warning=FALSE, message=FALSE}
edx %>% group_by(title) %>%
        summarise(n = n(), mu = mean(rating)) %>%
        slice_max(n, n=10) %>%
        select("Movie Name" = title, "No. of Ratings" = n, "Avg Rating" = mu) %>% 
        knitr::kable(caption = "Top 10 movie titles based on number of ratings")
```

## Plot average rating by year of release in the edx dataset
```{r, echo=FALSE, warning=FALSE, message=FALSE}
edx %>% group_by(release_year) %>%
  summarise(rating = mean(rating)) %>%
  ggplot(aes(release_year, rating)) +
  geom_point() +
  geom_smooth() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "Release Year", y = "Average Rating", caption = caption_text) + plot_theme
```

## Plot number of ratings by year of release in the edx dataset
```{r, echo=FALSE, warning=FALSE, message=FALSE}
edx %>% group_by(release_year) %>%
  summarise(count = n()) %>%
  ggplot(aes(release_year, count)) +
  geom_line() +
  scale_y_continuous(breaks = seq(0, 800000, 200000), labels = sprintf("%sK", seq(0, 800, 200))) +
  labs(x = "Release Year", y = "Number of Ratings (in 1000s)", caption = caption_text)
```

## Plot average rating by date of review in the edx dataset
```{r, echo=FALSE, warning=FALSE, message=FALSE}
edx %>% group_by(review_date) %>%
  summarize(rating = mean(rating)) %>%
  ggplot(aes(review_date, rating)) +
  geom_point() +
  geom_smooth() +
  labs(x = "Review Date", y = "Average Rating", caption = caption_text)
```

## Plot average rating by year of review in the edx dataset
```{r, echo=FALSE, warning=FALSE, message=FALSE}
edx %>% group_by(review_year) %>%
  summarize(rating = mean(rating)) %>%
  ggplot(aes(review_year, rating, label = round(rating, 2))) +
  scale_x_continuous("Year of Review", breaks = seq(1990, 2010, 1)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  geom_point() +
  geom_text(size = 3, hjust = 1, vjust = 2) +
  geom_smooth() +
  labs(x = "Year of Review", y = "Average Rating", caption = caption_text)
```

<!-------------------------------------------------------------------------------------------------------->
# Creation of training and test datasets

The edx dataset is divided into a training set and test set to develop and test different models. 90% of the data as the training set is used to train the models and these models are tested on the remaining 10% of the test dataset. The model with the best prediction (lowest RMSE) on the test set is used as final model to predict ratings for the validation set.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
set.seed(27, sample.kind="Rounding")
test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.1, list = FALSE)
edx_train <- edx[-test_index,]
edx_test <- edx[test_index,]

# Keep only those rows in edx_test and validation set which have 
# movieId and userId existing in edx_train dataset
edx_test <- edx_test %>% 
            semi_join(edx_train, by = "movieId") %>%
            semi_join(edx_train, by = "userId")

validation <- validation %>% 
              semi_join(edx_train, by = "movieId") %>%
              semi_join(edx_train, by = "userId")

```

**Training Set: edx_train**
```{r, echo=FALSE}
str(edx_train)
```

**Test Set: edx_test**
```{r, echo=FALSE}
str(edx_test)
```

**RMSE function that will be used for all the different models**

By definition, 
$$\mbox{RMSE} = \sqrt{\frac{1}{n}\sum_{t=1}^{n}(actualData - predictedData)^2}$$

R function defined as -
```{r, echo=TRUE}
RMSE <- function(actual_data, predicted_data){
  sqrt(mean((actual_data - predicted_data)^2))
}
```

# Development of different models and their performance

## Model 1.0: Simple mean of training set

```{r, echo=TRUE}
# Get the mean rating as prediction value
mu <- mean(edx_train$rating)
# Get the RMSE for test set using mu as prediction value
rmse_model1 <- RMSE(edx_test$rating, mu)
```

```{r, echo=FALSE, warning=FALSE}
rmse_table <- data_frame(method = "Model 1.0: Simple mean of training set", RMSE = rmse_model1)
rmse_table %>% knitr::kable(caption = "Simple Mean based Model")
```

## Model 2.x:  Models with single effects

### Model 2.1:  Mean with movie effect
```{r, echo=TRUE}
#Train on the edx training set to find movie effect
movie_effects     <-  edx_train %>% 
                      group_by(movieId) %>% 
                      summarize(b_m = mean(rating - mu))

#Generate predictions on the edx test set
predicted_ratings <-  mu + (edx_test %>% 
                              left_join(movie_effects, by='movieId') %>%
                              .$b_m)

#Find RMSE for this model
rmse_model_b_m <- RMSE(edx_test$rating, predicted_ratings)
```

\newpage

## Model 3.x:  Study of models involving two effects in different forms

### Model 3.1:  Mean with movie and user effect taken independently
```{r, echo=TRUE}
# Combine Model 2.1 & Model 2.2
# Generate predictions on the edx test set
predicted_ratings <-  edx_test %>% 
                      left_join(movie_effects, by='movieId') %>%
                      left_join(user_effects, by='userId') %>%
                      mutate(pred = mu + b_m + b_u) %>%
                      .$pred

# Find RMSE for this model
rmse_model_3_1 <- RMSE(edx_test$rating, predicted_ratings)
```

```{r, echo=FALSE}
# Add the new RMSE to the RMSE Table
captionTableType2 <- "RMSE Values for 3.x Model series"
rmse_table <- bind_rows(rmse_table,
                        data_frame(method="Model 3.1: Mean + Movie + User Effect",
                                   RMSE = rmse_model_3_1 ))
rmse_table %>% knitr::kable(caption = captionTableType2)
```

## Model 4.x: Towards the model involving all the effects

### Model 4.1:  Model of movie, user, genre effects in respective order
```{r, echo=TRUE}

```

```{r, echo=FALSE}

```

## Model 5.0: Effects of Regularization on the model

Regularization is a form of regression, that constrains/ regularizes or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, so as to avoid the risk of overfitting. Thus, to avoid overfit we will apply regularization and study its influence on the RMSE.

### Define function to find RMSE for given lambda on a predefined model

Regularization process involves finding out an optimal lambda to tune the model. A common function is defined to find the RMSE for particular lambda on Model 3.2.
```{r, echo=TRUE}

```

### Finding the optimal value of lambda
```{r, echo=TRUE, eval=TRUE}
# Towards optimal lambda - Step 1
lambdas <- seq(0, 100, 10)
rmses <- sapply(lambdas, function(l) {  find_rmse_for_lambda(l) })
qplot(x = lambdas, y = rmses, main = "Plot 1: Finding optimal lamda", 
      xlab = "Lamda", ylab = "RMSE", geom = c("point", "line"))
```
*Observation*: The optimal lambda seems to lie in the range of (0,10).

```{r, echo=TRUE, eval=TRUE}
# Towards optimal lambda - Step 2
lambdas <- seq(0, 10, 1)
rmses <- sapply(lambdas, function(l) {  find_rmse_for_lambda(l) })
qplot(x = lambdas, y = rmses, main = "Plot 2: Finding optimal lamda", 
      xlab = "Lamda", ylab = "RMSE", geom = c("point", "line"))
```
*Observation*: The optimal lambda lies between 4 and 6. Next, we'll find RMSE for models with lambda between 4 & 6 in steps of 0.1. The lambda with minimum RMSE is the optimal lambda for the above model.

```{r, echo=TRUE, eval=TRUE}
# Towards optimal lambda - Step 3
lambdas <- seq(4, 6, 0.1)
rmses <- sapply(lambdas, function(l) {  find_rmse_for_lambda(l) })
qplot(x = lambdas, y = rmses, main = "Plot 3: Finding optimal lamda", 
      xlab = "Lamda", ylab = "RMSE", geom = c("point", "line"))
```

```{r, echo=FALSE, eval=TRUE, message=FALSE}
# Print optimal lamda and corresponding rmse
lambdas[which.min(rmses)]
min_rmse <- min(rmses)
```

*Observation*: The optimal lambda is `r lambdas[which.min(rmses)]` that gives an RMSE of `r, min_rmse`.

```{r, echo=FALSE, eval=TRUE}
#Add the new RMSE to the RMSE Table
rmse_table <- bind_rows(rmse_table,
                        data_frame(method="Model 5.0: Mean + Regularized Movie + Cum. User Effect",
                                   RMSE = min_rmse))
rmse_table %>% knitr::kable(caption = "RMSE Values for All Models")
```
*Observation*: As observed in the regularized model, the RMSE value is `r min_rmse` against a non-regularized model that had an RMSE of `r rmse_model_3_2`. Therefore, we will use regularization along with all the features to train our final model.

## Model 6.0: Model with all features and regularization
```{r, echo=TRUE, eval=TRUE}
# Regularise model, predict ratings and calculate RMSE for passed value of lambda

```

# RMSE on validation set with final chosen model

```{r, echo=FALSE, eval=TRUE}

```

```{r, echo=TRUE, eval=TRUE}


```

<!-------------------------------------------------------------------------------------------------------->
# Conclusions
The MovieRecommenderModel developed predicts values on the validation set with an RMSE of `r final_rmse_validation_set`. The model includes the movie, user, genre, release year and review year effects along with regularization.

<!-------------------------------------------------------------------------------------------------------->
# References

[1] Introduction to Data Science, Rafael A. Irizarry \
[2] http://www.sthda.com/english/wiki/qplot-quick-plot-with-ggplot2-r-software-and-data-visualization \
[3] https://bookdown.org/yihui/rmarkdown-cookbook/kable.html \
[4] https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet \

\newpage
<!-------------------------------------------------------------------------------------------------------->

